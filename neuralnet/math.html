<div id="step-1-feed-forward" class="section level3">
<h3>Step 1: Feed Forward</h3>
<p>Each neuron in layer l receives weighted input from every neuron in layer l-1</p>
<p><span class="math display">\[z(x) = \sum_{i=1}^nw_ix_i+b\]</span></p>
<p>The weight matrix is stored as w_oi (output, input) so that the above equation can be completed for each neuron in a single dot product</p>
<pre><code>    I1  I2         
H1  w   w   dot  I1   =   H1z
H2  w   w        I2       H2z</code></pre>
<p>The output z is then feed into an activation function of several choices.</p>
<p>Sigmoid function</p>
<p><span class="math display">\[\sigma = \frac{1}{1+e^{-x}}\]</span></p>
<p>This squeezes all outputs into range 0..1 and prevents extreme values from affecting the output.</p>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYAAAAGACAMAAACTGUWNAAAAhFBMVEUAAAAAADoAAGYAOpAAZrYzMzM6AAA6kNtNTU1NTW5NTY5NbqtNjshmAABmkJBmtv9uTU1uq+SOTU2OyP+QOgCQ2/+rbk2r5P+2ZgC225C2///Ijk3I///bkDrb///kq27k5Kvk///r6+v/tmb/yI7/25D/5Kv//7b//8j//9v//+T////8VgDLAAAACXBIWXMAAB2HAAAdhwGP5fFlAAAMu0lEQVR4nO2d64LbthGFUce11dpp197WTaNulDqK41rv/36leJEAckCDAIiByO/8SBZiJkczn3iDKIy5IFUZ7TewdwFAWQBQFgCUBQBlAUBZAFAWAJQFAGUBQFkAUBYAlAUAZRUH8Pkm+29Bc1vnQ+MjS5gCQNkUAMqmAFA2BYCyKQCUTXMC+Prx/Wh8OBw+SAMAWIN8AI4HB8CXp8NV7/47GQDAHmQDcDw4AJqP/Pu28B/GAwA4g0wA2o+4DeDcfdy/PP31P6MBAJxBHgCnpvpnB8Cx+7R/+3R4Hg0A4AwyAfjLvy4OgG+fmlc6NB/cAQDWOgk7AL5+7I82p+ZVZ9Dqz71S/OqSCdfc/yXlLcgAzjaA86YALKh5dQAG1XQ0WBAqlTXOFACLQ301jzNdH4B8DnhUAPfS134S3uRVkP25rx1Ac+n/3IHo7gOswaMCcI861QPY2p3w+KBfPYBtzQUJ1zn1Avjy1B7xzwdrAtQZPB4A4ZKnfgAb+j5AuuKsEECMFtfiuxlljBxCxSt+AGSvhSfUc8cFgOy1kEN9d7wAyF4LOdQ34QCA7LUQQ70TPgDIXgsp1D/hBoDstZBCAbA4o4yRny8zM84AyF4LYfPcjD8ActdiqtmvXACQuxZjzX7lBYD8tRhp/jtHAOSvxUhN+QuYAsArAMRllC0SAHEZ5Ypsn3xY3xQAPpkypgDwyAAgMqM8kd0VKAAiMsoTCYDojPJEAiA6oyyRZjcAKtXsM/yrGpc2DP1EFd8DSpkCQBQA4jPKEXl7BH19UwAIuk1DAyAio/TI+9cAAIjIKD0SAEkZpUcCICmj5EgDgKSMkiPt34GtbwqAiQCQllFqpAFAWkapkfazKAAoWotOAEjMKDUSAIkZJUYaACRmlBjp/hp+fVMAjASA1IwSIwGQmlFapAFAakZpke4T6QAoWourAJCcUVokAJIzSoo0AEjOKCkydvHJeFMA2Ipe/TPeNBuA8YJM3z4dBl3XiWs393/XDKC4aS4AkwYNIwD9dgCMIzMB8C7Kd19A7r0QVhmAye9SHweAd1nKZkdomRyF9eIqBFDeNBMAb4OGU0fmtnQuAFYB4F2auDk0PXf/fvfr0/QMAIBMALyLc59uK1n2J+RhB6myf4DarwKstxAX5lueftgBruu2XneNYUXROgFUUP/cAM7DdemwJ1S9evp0bY7HOwS5AKbn5C9Po8WLQxMCQBgA9xwwvSqdvBKaEABm5bkKmt591bwHCMsDPQwAT4OG293XDVDNPWSkBbpXN131Tti6+xpQHCvuoPHQAMS5oNuZod3yfLGuigBwH2QB4DRoGK727QP+SZ4MBUAuAPb3AQMA5/Pebp/OiIYmBICVFJrQ+rUQmzSsbQoAAAQmBAAArGEKAAAEJrR6LeRGPSubfgYAAAITAgAAVjD9DAAABCYEgI0D8HTLW9e0GwDgKgAAYNcAfA07VzXtBwD47O1XBYBStQCALgBfwyoAFKqFt2fwmqbDAAAACEgIAADIbToMdAHUoRp+GdBpn3uAv2/8iqa3AQAAEJAQAACQ2fQ2AAAAAhICwIYB+DuXA6BILQAQkBAAAJDX9D4AAAACEgLAdgH46w+AIrUAQEhCAABAVlNrAAAABCQEgM0CmKk/AErUAgBBCQEAADlN7QEAFEztAQAUTO1BJgDj/gHjlgHT7QDoBnkATPoHjFoGCNvrADBX/wcCIK0ZZ6+Q6O0vEJoQAC6XP340r372bJNWTbRbBnj7C4QmBIAWQCOZgdA/wGkZ4O0vEJrQWrXw/TZmVdPoQ9CLMTIDaeVcu2WAt79ABQAUTFPOAT2DH35xXpXWjrZbBky317J8fT0PpncKeTsCA2n1dLtlwHR7JQDMIwJo9Psb91gkAbBbBvj6C6gfguaPQDUegq7qzsb2buAvcLd+LgC8kYsB/NaX/m0H4rULYNxD5tJdevq3hyYEgFYv9+r34+4o5L/K6faAaq+CHgrAcOR5e3/pZTgGTfsHuC0D5P4CAFgO4K28TbjTdVoG1Hon/GAAPNW/iHM9TsuASueCmovQ8qbrzIYK/QOclgH2dgA4gzwApP4BTsuAKr8P2BKASIUmBAAA5DIFwF0A0AVwnYkrbgqAuwAAAAAUNwXAXQAAwK4BGKP2OJ49AEBR03EkAAqbjiMBUNh0HAmAwqbjSAAUNh1HAqCw6ThyxwCu3wcDIDQhAAAgi+kkcr8ADAC0ASiYTiMBUNR0GqkNQE3V/TKg0372gO6hRPaA0IQAAIAMpkIkAEqaCpEAKGkqRO4VQP/DAACEJgQAAKSbSpEAKGgqRQKgoKkUCYCCplLkTgEMv44EQGhCAABAsqkYCYBypmIkAMqZipH7BHBboQAAoQkBAACppnIkAIqZypEAKGYqRwKgmKkcuUsA92WaABCaEAAAkGjqicwGQFiQqV28uF8kzu3mAABrkAeA0KDh2K8d/cHaDoBxZCYAwqJ8/drRx0O7fpmwpK4aAGupxM0AmF228v3F7eYAAGeQBcC0QYO7cKvTzUEZgNkggLmli1sAdjcHfQAKpt7IPABmFu/udgq7m0Mrxf4Bdf4woFcqgOm59tSeHexuDq30AFT6y4xe2QGcD/0quvduDo7KHw2c5aI3dwgaA+jrf9N1LXsAlDsHnEb1ny6fXr4WmwQgXwU159/xZQ97wDgyDwCxQUMzGKrt3hSoAnA7BmwGgHAnbNV/1M0BAM4gCwBhLuhkz8w53RwA4AyyAJg2cBjmn/sXT/JkKAByAZg0cDgfHABuNwc9AGazACJVuhajrj0AKF0LAABg1wDG/ZsBULgW48ZtAChcCwAAYNcAxqcAABQHsCgSALlrAQAAjCMBsLrpfOSuAEzbNwOgZC2E9tkAKFgLqX05AArWAgAAECIBsK7pdyP3A2AyDVHC9PuRewKwOBIAOWsBAF0A4hEIAOVU9a8C7tryHrA8cg97QLFaAEAXgFx/AJQC4Kk/AAAAgPVMgyL3AUC+CVjZNCxyFwC89QdAKQBxkQDIUwt//QFQBkBsJACy1GJmBwBAAQBz9QcAADYPwJj4KgIgvRbN5x8AigAMAFQBtLfAAFAD0E1BAEALQD8FBAAlAMMUHAB0ANymQAGgAuA+BQ2A8gCMsb4C2AkAoX+A85KwfTUATv13AkDoH+C8JGxfC4AZL8oUHJlgGh2ZCYCwZpzzkrB9FQDGmHH99wFAWDXReUnYnh+Akcq/EwDT/gHuS8L2rACMp/iLapEztDAAYeVc5yV/f4G0WhhXibXIGVoYgLB2tPPSdLuwfL1JUdz7rk/5Vk93XppuzwQg7u1WrGIABtV0NFAxBYCyaWYAwecAANwGOQBoXQXlrYWKaR4AUv8A5yWpvwAAukEWAFXcCWePfCAAtcwF5Y18IADT/gHuS+4AAPYgD4BJ/4CL4vcBuSIfCkCkaqqFiikAlE0BoGyqDeCuhMae8aHVmQJA2RQAyqYAUDYFgLIpAJRNAaBsCgBl0+19y/1gAoCyAKAsACgLAMoCgLIAoCw1AF8/3p/oEr+7nA/2dKwPCFvmlGYYkKUagOPwyJzvt0xz6mMW1iPGKckwJEstAMdD/9a8z6/MafLEaYiinFIMg7LUAdB+Hrq35n2Ca07HuCJGOKUYBmWpAuDUvK/hM+X9LdOMbk+eLlKMU4phWJY6AJp0+rfmf4p3Rl8/vvv1aekBOcopxTAsS7WTcP/W/M+xz2g4JS76KEc5pRhe9f0sqwGw5DR37i7ohgfywhTllGJoec14PySA4XO06GCSAiDK0PLaGoBBX54WXNMnOcUYWl51ADg7h9GIc8B5fBxedEWZcg6IMryqqnOACGDJtYkAYMEHMuUqKMrwqvqvgvy/ZfLrls6yg0mEU5rhJSRLdQAx96fDfelxUSkT7oTjDC8hWaoDiJmhaf7r58stq1AlzAXFGV5CslQH4P0t05xOUXOTMU5JhiFZ6gOImqVvYxZfzMR/HxBpGJAl34gpCwDKAoCyAKAsACgLAMoCgLIAoCwAKAsAygKAsgCgLAAoCwDKAoCyAKAsACgLAMoCgLL2A+D3N+Z1+8dP5k//VH4vlvYD4PJizN8vLYi32m/F0o4A/O8f5odf+n/Wox0B6D77L1UdgPYFoCn+q3/XdQDaGYA/fjSmrgPQzgBcfjOVHYD2BqDZBV79rP0mXO0LwE/NIei19ptwtSsAzRHob2/am4F6tCcAzQHodbMT1HUQ2hOAtvYthYq0IwD9HERld2L7ATDMQVQ2F7EfAP1cXHsqruhmeD8AKhUAlAUAZQFAWQBQFgCUBQBlAUBZAFAWAJQFAGUBQFkAUBYAlAUAZQFAWQBQFgCUBQBlAUBZ/wcLrCqQnaumjQAAAABJRU5ErkJggg==" width="192" /></p>
<p>The derivative of the sigmoid function is:</p>
<p><span class="math display">\[S'(x) = S(x) * ( 1.0 - S(x) )\]</span></p>
</div>
<div id="step-2-back-propogation" class="section level3">
<h3>Step 2: Back propogation</h3>
<p>Starting with the output layer the error is calculated for each neuron (where i is the expected:</p>
<p><span class="math display">\[E = (actual-expected)\]</span></p>
<p>Gradient descent calculates the gradient of the Error function for the given set of weights.</p>
<p><span class="math display">\[\frac{ \partial E}{\partial w_{(ik)}} = \delta_k \cdot o_i\]</span> Where the deltaâ€™s are:</p>
<p><span class="math display">\[\delta_i = \begin{cases}-E f'(z_i) &amp; \mbox{, output nodes}\\ f'(z_i) \sum_k w_{ki}\delta_k &amp; \mbox{, interier nodes}\\ \end{cases}\]</span></p>
<p>where i is each neuron in the current layer k is each neuron in the backwards prior layer (ie current layer + 1)</p>
<p>Note interior deltas are calculated from the delta in the backwards prior layer.</p>
<p>Weights are updated to go down the gradient (ie to minimize the error)</p>
<p><span class="math display">\[w_k = w_k-\eta \sum_j \frac{\partial E_{X_j}}{\partial w_k} \label{deltaw}\]</span></p>
</div>
